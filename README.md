# ü§ñ Projet CATRONIC : Robot Autonome "Chat et Souris"

<p align="center">
  <img src="Media/logo_catronic.jpg" alt="Logo Catronic" width="200"/>
</p>

> **Auteurs :** AFIF Ikram, AIT ALLA Hajar, MENJLI Fakhri  
> **Ann√©e acad√©mique :** 2025/2026

Le robot **CATRONIC** est un syst√®me embarqu√© autonome con√ßu pour simuler un jeu de chat et de souris entre plusieurs robots identiques. Les robots √©voluent sur une table sans bordures et sont capables de d√©tecter les bords pour √©viter toute chute.

---

##  Table des mati√®res
- [Strat√©gie de fonctionnement](#strat√©gie-de-fonctionnement)
- [Architecture du syst√®me](#architecture-du-syst√®me-global)
  - [Sch√©mas g√©n√©raux](#sch√©mas-g√©n√©raux)
  - [Sous-syst√®mes](#sous-syst√®mes)
- [Nomenclature (Bill of Materials)](#nomenclature-bill-of-materials)
- [Structure logicielle et FreeRTOS](#structure-logicielle-et-freertos)
- [Tests et validation](#tests-et-validation)
- [Test final](#test-final)
- [Conclusion](#conclusion)

---

##  Strat√©gie de fonctionnement

La logique du robot est orchestr√©e par un noyau temps r√©el (**FreeRTOS**), permettant de g√©rer plusieurs t√¢ches simultan√©ment pour une r√©activit√© maximale.

### D√©tection de l'environnement

- **D√©tection des bords :** Le robot utilise des **capteurs m√©caniques W√ºrth WS-MITV** positionn√©s √† l‚Äôavant, √† l‚Äôarri√®re, √† gauche et √† droite. Lorsqu‚Äôun capteur d√©tecte le vide, il d√©clenche une interruption qui ordonne un changement imm√©diat de direction pour √©viter la chute.  
- **D√©tection des adversaires :** Le **LIDAR YDLIDAR X2** scanne l‚Äôenvironnement √† 360¬∞ et transmet en temps r√©el la position et la distance des autres robots.  
- **D√©tection des collisions :** L‚Äô**acc√©l√©rom√®tre ADXL343** d√©tecte les chocs par variation brutale d‚Äôacc√©l√©ration. Il est √©galement utilis√© comme arr√™t d‚Äôurgence manuel.

### Modes de jeu

- **Mode Souris üê≠ :** Le robot cherche √† maximiser la distance avec le ‚Äúchat‚Äù tout en √©vitant les bords de la table.  
- **Mode Chat üê± :** Le robot identifie la ‚Äúsouris‚Äù la plus proche via le LIDAR et cherche √† la percuter.

---

##  Architecture du syst√®me global

L‚Äôarchitecture est organis√©e autour de cinq sous-ensembles principaux : **alimentation**, **commande**, **acquisition**, **d√©placement** et **interface utilisateur**.

### Sch√©mas g√©n√©raux

Vues d‚Äôensemble de l‚Äôarchitecture mat√©rielle :

**Figure 1 ‚Äì Diagramme d‚Äôarchitecture fonctionnelle du robot:**

![Diagramme d'architecture](Media/diagramme_architecture.png)

**Figure 2 ‚Äì Sch√©ma global du syst√®me:**

![Sch√©ma global](Media/schema_global.jpg)

**Figure 3 ‚Äì Routage du PCB principal:**

![PCB Catronic](Media/pcb_catronic.jpg)

**Figure 4 ‚Äì Vue 3D du PCB sous KiCad:**

![Vue 3D du PCB](Media/pcb2.jpg)


### Sous-syst√®mes

####  Alimentation
Le robot est aliment√© par une batterie **NiMH 7.2V**, r√©gul√©e en **5V** pour le LIDAR et en **3.3V** pour le reste des composants.

![Sch√©ma d'alimentation](Media/schema_alimentation.jpg)
*Figure 5 ‚Äì Sch√©ma d‚Äôalimentation du robot.*

####  Commande
Le c≈ìur du syst√®me repose sur un **STM32G431CBU6** (ARM Cortex-M4) ex√©cutant **FreeRTOS** pour coordonner les diff√©rentes t√¢ches.

![Sch√©ma STM32](Media/schema_stm32.jpg)

*Figure 6 ‚Äì Sch√©ma de la carte de commande STM32.*

#### Acquisition
Ce sous-syst√®me regroupe les capteurs assurant la perception de l‚Äôenvironnement.

![Sch√©ma des capteurs (sensors)](Media/sensors.jpg)

*Figure 7 ‚Äì Sous-syst√®me de d√©tection (LIDAR, acc√©l√©rom√®tre, capteurs WS-MITV).* 

####  D√©placement
Deux moteurs DC, command√©s par des **drivers ZXBM5210-SP-13**, permettent un contr√¥le pr√©cis de la vitesse et de la direction via des signaux PWM.

![Sch√©ma des actionneurs](Media/Sch√©ma_capteurs.jpg)

*Figure 8 ‚Äì Sch√©ma des moteurs et drivers.*

####  Interface utilisateur
Interrupteur, bouton de d√©marrage, LED de statut et connecteur SWD pour le d√©bogage.

---

##  Nomenclature (Bill of Materials)

| Composant | R√©f√©rence | Datasheet |
|:---|:---|:---|
| Microcontr√¥leur | STM32G431CBU6 | [Datasheet](https://www.st.com/resource/en/datasheet/stm32g431c6.pdf) |
| Driver moteur | ZXBM5210-SP-13 | [Datasheet](https://www.mouser.fr/datasheet/3/175/1/ZXBM5210.pdf) |
| Acc√©l√©rom√®tre | ADXL343BCCZ-RL | [Datasheet](https://www.analog.com/media/en/technical-documentation/data-sheets/adxl343.pdf) |
| LIDAR | YDLIDAR X2 | [Datasheet](https://cdn.robotshop.com/media/y/ydl/rb-ydl-04/pdf/ydlidar-x2-360-laser-scanner-datasheet2.pdf) |
| R√©gulateur 5V | MP1475DJ-LF-P | [Datasheet](https://www.farnell.com/datasheets/2915024.pdf) |
| R√©gulateur 3.3V | BU33SD5WG-TR | [Datasheet](https://fscdn.rohm.com/en/products/databook/datasheet/ic/power/linear_regulator/buxxsd5wg-e.pdf) |
| Batterie | NiMH 7.2V 1.3Ah | [Datasheet](https://fr.rs-online.com/web/p/blocs-batteries-rechargeables/7770377) |
| Capteur bordure | WS-MITV THT | [Datasheet](https://www.we-online.com/en/components/products/MITV_12_8X5_8_THT__LEVER_LEFT_55GF) |
| Bluetooth | HC-05 | [Datasheet](https://components101.com/sites/default/files/component_datasheet/HC-05%20Datasheet.pdf) |
| Boutons poussoirs | Wurth 430182070816 | [Datasheet](https://www.we-online.com/components/products/datasheet/430182070816.pdf) |
| Interrupteur ON/OFF | Wurth 472121020311 | [Datasheet](https://www.we-online.com/components/products/datasheet/472121020311.pdf) |

---
## Fichiers sources principaux

-   **`main.c`** : Point d'entr√©e du programme. Ce fichier initialise le microcontr√¥leur, tous les p√©riph√©riques (GPIO, I2C, UART, Timers), les pilotes (moteurs, LIDAR), et cr√©e les quatre t√¢ches FreeRTOS qui orchestrent le comportement du robot.
-   **`robot_logic.c`** : C≈ìur de l'intelligence du robot. Il contient l'impl√©mentation des t√¢ches FreeRTOS qui g√®rent la logique de jeu, la d√©tection des collisions et des bordures, ainsi que la communication.
-   **`MoteurPWM.c`** : Pilote pour le contr√¥le des moteurs DC. Il fournit des fonctions pour initialiser les moteurs, et contr√¥ler leur vitesse via des signaux PWM.
-   **`ADXL343_driver.c`** : Pilote pour l'acc√©l√©rom√®tre ADXL343. Il g√®re l'initialisation du capteur et la d√©tection de chocs.
-   **`driver_LIDAR.c`** : Pilote pour le capteur LIDAR YDLIDAR X2. Il traite les donn√©es brutes re√ßues via UART DMA pour en extraire la distance et l'angle des obstacles.
-   **`border_sensors.c`** : G√®re la logique des capteurs de bordure.
-   **`drv_bt.c`** : Assure la gestion de la communication Bluetooth (HC-05), notamment la r√©ception de commandes.

##  Structure logicielle et FreeRTOS

Le comportement du robot est g√©r√© par **quatre t√¢ches FreeRTOS** principales :

1.  **`BorderTask`**
    -   **R√¥le :** Surveille en permanence les capteurs de bordure.
    -   **Fonctionnement :** √Ä intervalle r√©gulier (100 ms), la t√¢che lit l'√©tat des capteurs. Si un bord est d√©tect√©, elle met √† jour une variable globale (`border_active`) prot√©g√©e par un mutex pour signaler l'√©tat et la direction du bord d√©tect√© √† la t√¢che principale `RobotModeTask`.

2.  **`ShockTask`**
    -   **R√¥le :** D√©tecte les collisions et inverse les r√¥les "Chat" et "Souris".
    -   **Fonctionnement :** La t√¢che initialise l'acc√©l√©rom√®tre pour la d√©tection de chocs. Elle v√©rifie en continu si un choc a eu lieu. Si c'est le cas, elle change l'√©tat du robot (`robot_mode`) de `CHAT` √† `SOURIS` ou inversement.

3.  **`BluetoothTask`**
    -   **R√¥le :** Traite les commandes re√ßues via Bluetooth.
    -   **Fonctionnement :** La t√¢che attend de recevoir des commandes utilisateur. Elle peut ainsi forcer le robot √† s'arr√™ter (`STOP`), √† d√©marrer (`START`), ou √† passer en mode `CHAT` ou `SOURIS`, offrant un contr√¥le manuel sur le comportement du robot.

4.  **`RobotModeTask`**
    -   **R√¥le :** T√¢che principale qui ex√©cute la logique de d√©placement et de jeu.
    -   **Fonctionnement :** C'est la t√¢che la plus complexe. √Ä chaque cycle :
        -   Elle v√©rifie l'√©tat de la variable `border_active`. Si un bord est d√©tect√©, elle ex√©cute une man≈ìuvre d'√©vitement prioritaire (reculer puis tourner) pour emp√™cher le robot de tomber.
        -   Si aucun bord n'est d√©tect√©, elle ex√©cute la logique de jeu en fonction de la variable `robot_mode` :
            -   **Mode `ROBOT_STOP` :** Les moteurs sont √† l'arr√™t.
            -   **Mode `ROBOT_MODE_CHAT` (Poursuite) :** La t√¢che analyse les donn√©es du LIDAR pour trouver l'obstacle le plus proche. Si l'obstacle est en face, elle commande au robot d'avancer. Sinon, elle le fait tourner pour se diriger vers la cible.
            -   **Mode `ROBOT_MODE_SOURIS` (Fuite) :** Si un obstacle (le "chat") est d√©tect√© √† moins de 30 cm, le robot recule pour s'en √©loigner. Sinon, il continue d'avancer pour explorer la zone de jeu.
        -   Si aucun obstacle n'est d√©tect√© par le LIDAR, le robot s'arr√™te.

---

##  Tests et validation

Pour garantir la fiabilit√© du syst√®me, plusieurs s√©ries de tests ont √©t√© men√©es.

### Test de d√©placement et moteurs

Ce test valide le contr√¥le PWM et met en √©vidence les √©carts de vitesse entre les moteurs. 
Un ajustement asym√©trique des vitesses a permis d‚Äôam√©liorer la pr√©cision du d√©placement du robot.

![Test moteur](Media/test_moteur.jpg)

### Test de d√©tection de bordures/d√©tection de collision

Ce test est crucial pour la s√©curit√© du robot. Il valide la robustesse des capteurs m√©caniques, et la d√©tection des chocs via l'acc√©l√©rom√®tre qui d√©clenche le changement de r√¥le du robot
- **Approche frontale :** Le robot est dirig√© droit vers le bord de la table. On v√©rifie qu'il s'arr√™te et recule √† chaque fois, sans chute.
- **Approche en diagonale :** Le test est r√©p√©t√© avec diff√©rents angles d'approche pour s'assurer que le levier du capteur est bien actionn√© m√™me lorsque le robot n'est pas perpendiculaire au bord.
- **Fiabilit√© :** R√©p√©tition du test des dizaines de fois pour garantir la reproductibilit√© et la fiabilit√© du m√©canisme.
- **Changement de mode apr√®s impact :** Apr√®s une collision d√©tect√©e par l'acc√©l√©rom√®tre, on v√©rifie que les r√¥les "Chat" et "Souris" sont bien invers√©s.

![Test bordures/chocs](Media/test1.jpg)

*Figure 9 ‚Äì D√©tection de bordures/chocs et changement de direction.*


### Test du LIDAR et logique de jeu

Ce test valide la perception de l'environnement et la strat√©gie comportementale.
- **Fiabilit√© de la d√©tection d'adversaire :** V√©rification que le LIDAR d√©tecte de mani√®re fiable la position de l'autre robot.
- **Logique de poursuite/fuite :** Validation de la trajectoire du robot en fonction des donn√©es du LIDAR (le "Chat" se rapproche de la "Souris", et la "Souris" s'en √©loigne).

![Test LIDAR](Media/test_lidar.jpg)

*Figure 10 ‚Äì Donn√©es LIDAR captur√©es via Tera Term (UART DMA).* 

### Test Bluetooth

Ce test v√©rifie la connectivit√© et la fiabilit√© de la communication sans fil via le module Bluetooth HC-05.

- **Connexion :** V√©rification de l'√©tablissement de la connexion Bluetooth avec un appareil externe.

- **Transmission de donn√©es :** Test de l'envoi et de la r√©ception de donn√©es entre le robot et l'appareil connect√©.

- **Changement de mode √† distance :** Validation de la capacit√© √† modifier le r√¥le du robot (Chat/Souris) via une commande Bluetooth.


![Test Bluetooth](Media/test2.jpg)

*Figure 11 ‚Äì Communication Bluetooth et affichage des donn√©es.*

---
## Structure du d√©p√¥t GitHub

```
‚îú‚îÄ‚îÄ Firmware/           ‚Üí Code STM32CubeIDE 
‚îú‚îÄ‚îÄ Hardware/           ‚Üí Sch√©mas, PCB et vues 3D KiCad
‚îú‚îÄ‚îÄ Media/              ‚Üí Illustrations et r√©sultats de tests
‚îî‚îÄ‚îÄ README.md           ‚Üí Pr√©sentation du projet
```

---
##  Test final


![Final Robot Test](Media/final_test.gif)

Lors du test final, le robot a valid√© plusieurs fonctionnalit√©s cl√©s. Les capteurs de bordure fonctionnent correctement, permettant au robot de d√©tecter les limites de la surface et d‚Äô√©viter toute chute. La commande via Bluetooth est √©galement op√©rationnelle : il est possible de s√©lectionner le mode de fonctionnement du robot ainsi que d‚Äôenvoyer des commandes Start et Stop pour lancer ou arr√™ter le syst√®me. Les donn√©es du LiDAR ont pu √™tre lues avec succ√®s, cependant toutes les mesures n‚Äô√©taient pas fiables et l‚Äôint√©gration compl√®te du capteur dans le syst√®me embarqu√© n‚Äôa pas pu √™tre finalis√©e. En cons√©quence, le robot n‚Äôest pas capable de d√©tecter les autres robots √† ce stade. Enfin, l‚Äôacc√©l√©rom√®tre permet de d√©tecter les chocs lors d‚Äôune collision, d√©clenchant automatiquement un changement de mode de fonctionnement du robot.






---
## Conclusion

Ce projet a permis de concevoir et de mettre en ≈ìuvre un robot mobile int√©grant plusieurs capteurs et modes de fonctionnement. Les tests finaux ont valid√© avec succ√®s la d√©tection des bordures, la commande via Bluetooth avec s√©lection des modes ainsi que la gestion des collisions √† l‚Äôaide de l‚Äôacc√©l√©rom√®tre. Ces fonctionnalit√©s assurent un fonctionnement s√ªr et contr√¥lable du robot.

Cependant, certains d√©fis techniques ont √©t√© rencontr√©s, notamment lors de l‚Äôexploitation et de l‚Äôint√©gration du LiDAR. Bien que les donn√©es aient pu √™tre lues, leur fiabilit√© et leur int√©gration compl√®te dans l‚Äôarchitecture embarqu√©e n‚Äôont pas pu √™tre finalis√©es, emp√™chant la d√©tection des autres robots. Ces limitations sont principalement li√©es aux contraintes de temps et √† la complexit√© du traitement des donn√©es capteur.

Ce travail a n√©anmoins permis d‚Äôacqu√©rir une exp√©rience pratique solide en syst√®mes embarqu√©s, en communication sans fil et en int√©gration capteurs. Des perspectives d‚Äôam√©lioration incluent l‚Äôoptimisation du traitement des donn√©es LiDAR, l‚Äôam√©lioration de la fusion capteurs et l‚Äôextension des capacit√©s de d√©tection du robot.

---

<p align="center">
  2026 ‚Äî Projet acad√©mique ENSEA
  <br>D√©veloppement d‚Äôun robot autonome Chat‚ÄìSouris 
</p>

